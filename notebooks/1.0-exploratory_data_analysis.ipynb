{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6c43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir, 'src')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3165aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aaf291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.extraction import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9d360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f227067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981 entries, 0 to 980\n",
      "Data columns (total 35 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   main_name             981 non-null    object \n",
      " 1   subtitle              981 non-null    object \n",
      " 2   link                  981 non-null    object \n",
      " 3   location              981 non-null    object \n",
      " 4   price                 981 non-null    object \n",
      " 5   attributes            981 non-null    object \n",
      " 6   timestamp             981 non-null    object \n",
      " 7   id                    981 non-null    int64  \n",
      " 8   address               702 non-null    object \n",
      " 9   since                 981 non-null    object \n",
      " 10  description           981 non-null    object \n",
      " 11  vendor                981 non-null    object \n",
      " 12  lat                   981 non-null    float64\n",
      " 13  lon                   981 non-null    float64\n",
      " 14  price_mod             981 non-null    float64\n",
      " 15  price_currency        981 non-null    object \n",
      " 16  since_period          981 non-null    object \n",
      " 17  since_value           981 non-null    int64  \n",
      " 18  days_on_site          981 non-null    float64\n",
      " 19  amenities             504 non-null    float64\n",
      " 20  age_in_years          981 non-null    float64\n",
      " 21  bathrooms             981 non-null    float64\n",
      " 22  cellars               52 non-null     float64\n",
      " 23  num_floors            84 non-null     float64\n",
      " 24  monthly_fee           128 non-null    object \n",
      " 25  apartments_per_floor  15 non-null     float64\n",
      " 26  disposition           20 non-null     object \n",
      " 27  parking_lots          981 non-null    int64  \n",
      " 28  floor_situated        24 non-null     float64\n",
      " 29  orientation           8 non-null      object \n",
      " 30  num_bedrooms          981 non-null    float64\n",
      " 31  department_type       39 non-null     object \n",
      " 32  m2                    981 non-null    float64\n",
      " 33  final_price           981 non-null    float64\n",
      " 34  price_square_meter    981 non-null    float64\n",
      "dtypes: float64(15), int64(3), object(17)\n",
      "memory usage: 268.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.extract('raw', 'reto_precios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7beebdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def clean_main_name(df=data.raw):\n",
    "#    for name in df['main_name']:\n",
    "#        [word for word in df['main_name'] if word not in df['location'].split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcfe12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicated_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes features that have the same data as other features. \n",
    "    Input:\n",
    "    \n",
    "    Returns:\n",
    "    New dataframe without duplicated data.\n",
    "    \"\"\"\n",
    "    # Assert features are really duplicated. And run a baseline, showing that is safe to delete the following columns, given that linear regression sets values of close to 0 for them.\n",
    "    \n",
    "    df.drop(['id', # PK: here it is not useful.\n",
    "             'address', # Subset of the feature \"location\".\n",
    "             'link', # The link by itself is not useful. Nevertheless, I might consider its use as an external source of information.\n",
    "             'price_mod', # The problem we are solving is a function of price_mod. If we leave it we can use it to compute price_mod / m2 and get price_square_meter. In this case, it would be useless to use other features.\n",
    "             #'m2', # The problem we are solving is a function of m2. If we leave it we can use it to compute price_mod / m2 and get price_square_meter. In this case, it would be useless to use other features.\n",
    "             #'final_price', # The problem we are solving is a function of final_price. If we leave it we can use it to compute price_mod / m2 and get price_square_meter. In this case, it would be useless to use other features.\n",
    "             'price', # The problem we are solving is a function of price. If we leave it we can use it to compute price_mod / m2 and get price_square_meter. In this case, it would be useless to use other features.\n",
    "             'attributes', # This feature's data has been extracted, and used to make new features. Such as: m2, num_bedrooms.\n",
    "             'main_name', # The information here is either trivial or has been used to make new features. Such as: subtitle\n",
    "             'since', # This feature's data has been extracted, and used to make new features. Such as: since_period, since_value and days_on_site.\n",
    "             'age_in_years', # Doesn't have information.\n",
    "             'subtitle', # Constant (no change)\n",
    "             'price_currency'# Constant (no change)\n",
    "            ], axis=1, inplace=True)\n",
    "    \n",
    "    return df   \n",
    "\n",
    "  \n",
    "    \"\"\"\n",
    "    Looks like \"price\" equals \"final_price\". If true remove \"price\"\n",
    "    \"\"\"\n",
    "    \n",
    "    #can_remove_feature = True\n",
    "    #for price, price_text in list(zip(df['final_price'],df['price'])):\n",
    "    #    if str(int(price)) not in price_text.split():\n",
    "    #        print('Can not remove \"price\" feature, given that not all rows are equivalent to \"final_price\" feature')\n",
    "    #        can_remove_feature = False\n",
    "    #if can_remove_feature: \n",
    "    #    df.drop('price', axis=1 ,inplace=True)\n",
    "    #    print(f'Removed \"price\" given that \"price_final\" = \"price\"')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Remove columns that have the same values on all rows\n",
    "    \"\"\"\n",
    "    #if len(df.columns) < 2:\n",
    "    #    return df\n",
    "    #for index, feature1 in enumerate(df):\n",
    "    #    for feature2 in df.columns[index+1:]:\n",
    "    #        if df[feature1].equals(df[feature2]):\n",
    "    #            df.drop(feature2, axis=1, inplace=True)\n",
    "    #            print(f'Removed \"{feature2}\" given that \"{feature1}\" = \"{feature2}\"')\n",
    "                \n",
    "    \"\"\"\n",
    "    \"attributes\" appear equal to \"num_bedrooms\" and \"m2\". Verify and remove \"attributes\" if equal.\n",
    "    \"\"\"\n",
    "    #not_found_values_count = 0\n",
    "    #for index, row in enumerate(df['attributes']):\n",
    "    #    values = ' '.join(row.split(',')).split()\n",
    "    #    if str(df['num_bedrooms'][index].astype(int)) not in values and str(df['m2'][index].astype(int)) not in values:\n",
    "    #        print(f\"{str(df['num_bedrooms'][index])} or {str(df['m2'][index])} are not in {values}\")\n",
    "    #        not_found_values_count += 1 \n",
    "    #if not_found_values_count == 0:\n",
    "    #    df.drop(['attributes'], axis=1, inplace=True)\n",
    "        \n",
    "    \"\"\"\n",
    "    \"Since\" this feature's data has been extracted, and used to make new features. Such as: since_period, since_value and days_on_site.\n",
    "    \"\"\"\n",
    "    #def get_total_days_since_publication(df):\n",
    "    #    for index, row in enumerate(df['since']):\n",
    "    #        row = row.replace('días', '1')\n",
    "    #        row = row.replace('día', '1')\n",
    "    #        row = row.replace('meses', '30')\n",
    "    #        row = row.replace('mes', '30')\n",
    "    #        row = row.replace('años', '365')\n",
    "    #        row = row.replace('año', '365')\n",
    "\n",
    "    #        text = row.split()\n",
    "    #        values = []\n",
    "    #        for string in text:\n",
    "    #            if string.isdigit():\n",
    "    #                values.append(int(string))\n",
    "    #        df['since'][index] = np.prod(values)\n",
    "    #    #df['since'].astype('int')\n",
    "    #    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e160b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first dtype different from NoneType in a series\n",
    "def find_dtype(series):\n",
    "    for value in series:\n",
    "        if type(value) != type(None):\n",
    "            return type(value)\n",
    "        \n",
    "def fix_nans(df):\n",
    "    for feature in df:\n",
    "        #if find_dtype(series=trxn[str(feature)]) == pd._libs.tslibs.nattype.NaTType:\n",
    "        #    trxn[str(feature)].fillna('NA', inplace=True)\n",
    "        if find_dtype(series=df[str(feature)]) == int or find_dtype(series=df[str(feature)]) == float:\n",
    "            df[str(feature)].fillna(0, inplace=True)\n",
    "        else:\n",
    "            df[str(feature)].fillna('NA', inplace=True)\n",
    "    return df\n",
    "\n",
    "def fix_monthly_fee(df):\n",
    "    for index, row in enumerate(df['monthly_fee']):\n",
    "        text = row.split()\n",
    "        for string in text:\n",
    "            if string.isdigit():\n",
    "                df.loc[index, 'monthly_fee'] = int(string)\n",
    "                break\n",
    "            else:\n",
    "                df.loc[index, 'monthly_fee'] = 0\n",
    "            #print(text, df['monthly_fee'][index])\n",
    "    df['monthly_fee'] = df['monthly_fee'].astype('int')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e764acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_codes(df, categorical_features):\n",
    "    df[categorical_features]=df[categorical_features].astype('category')\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        df[feature] = df[feature].cat.codes\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def sort_df_dtype(df):\n",
    "    \n",
    "    objects = df[df.select_dtypes(include='object').columns]\n",
    "    categories = df[df.select_dtypes(include='int8').columns]\n",
    "    integers = df[df.select_dtypes(include='int').columns]\n",
    "    floats = df[df.select_dtypes(include='float').columns]\n",
    "    \n",
    "    return pd.concat([objects, categories, integers, floats], axis=1)\n",
    "\n",
    "\n",
    "def normalize_features(df):\n",
    "    new_df = df.select_dtypes(['int8', 'int16', 'int32', 'int64', 'float64', 'float16', 'float32'])\n",
    "    \n",
    "    mean = new_df.mean()\n",
    "    std = new_df.std()\n",
    "    new_df = (new_df - mean) / std\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ddf4f35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7508/1670916047.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'int8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int16'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int32'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int64'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float64'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float16'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float32'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.select_dtypes(['int8', 'int16', 'int32', 'int64', 'float64', 'float16', 'float32']).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8cbdd1",
   "metadata": {},
   "source": [
    "# Extract, Transform, Load (ETL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb23616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applied priciples \"Dimensionality reduction\", \"Better perfomance: Optimized size of data\", \"Converted text classes to categorical codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08099e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_duplicated_features(df=data.raw.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d537215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fix_nans(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fix_monthly_fee(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['subtitle',\n",
    "                            'vendor',\n",
    "                            'price_currency',\n",
    "                            'since_period',\n",
    "                            'disposition',\n",
    "                            'orientation',\n",
    "                            'department_type']\n",
    "df = get_cat_codes(df, categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sort_df_dtype(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e756f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be561ad9",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering of departments for sale, data distribution, visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary\n",
    "#import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa46519",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:,9:]\n",
    "x_labels = features.columns\n",
    "features = features.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=features)\n",
    "_ = ax.set_xticklabels(x_labels, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7894ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the function parameters have been set we can visualize price_square_meter vs some_feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367814a",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63042d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download external data. Engineer new features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f215a5",
   "metadata": {},
   "source": [
    "### Geocoding web service\n",
    "\n",
    "    Used to correctly extract the location data. Since we have the (lat, lon) coordinates we can find the address attributes. \n",
    "    It is better this way, because the first record in our dataset has an incorrect neighbourhood \"Roma Sur\". \n",
    "    The correct neighbourhood is \"Roma Norte\" since \"Calle Sinaloa 20\" is located in the neighbourhood \"Roma Norte\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ccecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55424f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_attributes(data=data.raw):\n",
    "    \n",
    "    mayoralties = get_mayoralties()\n",
    "    \n",
    "    location_data = {'road': [], 'neighbourhood': [], 'postcode': [], 'mayoralty': [],\n",
    "                    'city': [], 'state': [], 'country': []}\n",
    "    geolocator = Nominatim(user_agent=\"uteyechea@gmail.com\")\n",
    "    for i in range(len(data)):\n",
    "        lat = data['lat'][i]\n",
    "        lon = data['lon'][i]\n",
    "        location = geolocator.reverse(f\"{str(lat)}, {str(lon)}\")\n",
    "        \n",
    "        try:\n",
    "            location_data['road'].append(location.raw['address']['road'])\n",
    "        except:\n",
    "            location_data['road'].append('NA')\n",
    "            \n",
    "        try:    \n",
    "            location_data['neighbourhood'].append(location.raw['address']['neighbourhood'].replace('Colonia ', ''))\n",
    "        except:\n",
    "            location_data['neighbourhood'].append('NA')\n",
    "            \n",
    "        try:\n",
    "            location_data['postcode'].append(location.raw['address']['postcode'])\n",
    "        except:\n",
    "            location_data['postcode'].append('NA')\n",
    "               \n",
    "        try:\n",
    "            mayoralty = [string.strip() for string in location.raw['display_name'].split(',') if string.strip() in mayoralties][0]\n",
    "            location_data['mayoralty'].append(mayoralty)\n",
    "        except:\n",
    "            location_data['mayoralty'].append('NA')\n",
    "            \n",
    "        try:\n",
    "            location_data['city'].append(location.raw['address']['city'])\n",
    "        except:\n",
    "            location_data['city'].append('NA')\n",
    "            \n",
    "        try:\n",
    "            location_data['state'].append(location.raw['address']['state'])\n",
    "        except:\n",
    "            location_data['state'].append('NA')\n",
    "            \n",
    "        try:\n",
    "            location_data['country'].append(location.raw['address']['country'])\n",
    "        except:\n",
    "            location_data['country'].append('NA')     \n",
    "        \n",
    "    location_data = pd.DataFrame(location_data)\n",
    "        #if save_to_disk:\n",
    "        #    location_data = pd.DataFrame(location_data)\n",
    "        #    location_data.to_csv(os.path.join(data.data_dir, 'external', 'location_data.csv'))\n",
    "    \n",
    "    return location_data\n",
    "\n",
    "def add_location_attributes(df: pd.DataFrame(), location_data: pd.DataFrame): \n",
    "    try:\n",
    "        df.drop('location', axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    new_df = pd.concat([location_data, df], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55084458",
   "metadata": {},
   "source": [
    "### Índice de Desarrollo Social de la Ciudad de México, 2020 \n",
    "\n",
    "    Es una medida ponderada que integra las dimensiones de vivienda, \n",
    "    acceso a servicios sanitarios (agua, drenaje y excusado), \n",
    "    adecuación energética, acceso a internet y disponibilidad de telefonía (fija o celular), \n",
    "    así como el rezago educativo, el acceso a los servicios de salud y a la seguridad social."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idsm():\n",
    "    indice_desarrollo_social = pd.read_csv(os.path.join(data.data_dir, 'external', 'ids_alcaldias.csv')).fillna('NA')\n",
    "    return indice_desarrollo_social\n",
    "\n",
    "def get_mayoralties():\n",
    "    indice_desarrollo_social = get_idsm()\n",
    "    mayoralties = indice_desarrollo_social['alcaldia'].unique()\n",
    "    return mayoralties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d252d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idsm(df):\n",
    "    desarrollo_social = get_idsm()\n",
    "    \n",
    "    ids = {'ids': []}\n",
    "    for i, mayoralty in enumerate(df['mayoralty']):\n",
    "        ids['ids'].append(desarrollo_social[desarrollo_social['alcaldia']==mayoralty].iloc[0,3])\n",
    "    \n",
    "    ids = pd.DataFrame(ids)\n",
    "    new_df = pd.concat([ids, df], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d208e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"uteyechea@gmail.com\") \n",
    "lat = 19.409823\n",
    "lon = -99.162138\n",
    "location = geolocator.reverse(f\"{str(lat)}, {str(lon)}\")\n",
    "location.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d98809",
   "metadata": {},
   "source": [
    "### Code execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b102d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_data = get_location_attributes()\n",
    "df = add_location_attributes(df, location_data)\n",
    "df = add_idsm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89425a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd209f0",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use a linear regresion model. It is a simple model that allows to compute price_per_square as a function of all available features. It will also allow us to see the distribution of weights associated with each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, use_bias=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd863599",
   "metadata": {},
   "source": [
    "### Before external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:, :-1]\n",
    "target_df = df.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f78dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "history = model.fit(train_df, target_df, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59134d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = range(len(train_df.columns)),\n",
    "        height=model.layers[0].kernel[:,0].numpy())\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(len(train_df.columns)))\n",
    "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a9a2e",
   "metadata": {},
   "source": [
    "### After external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefda4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf40f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['ids','road',\n",
    "                            'neighbourhood',\n",
    "                            'postcode',\n",
    "                            'mayoralty',\n",
    "                            'city',\n",
    "                            'state']\n",
    "df = get_cat_codes(df, categorical_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbaa2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sort_df_dtype(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1317f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['subtitle', 'price_currency'], axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6cd106",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:, :-1]\n",
    "target_df = df.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539dd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, use_bias=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afca059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "history = model.fit(train_df, target_df, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ce75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = range(len(train_df.columns)),\n",
    "        height=model.layers[0].kernel[:,0].numpy())\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(len(train_df.columns)))\n",
    "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
